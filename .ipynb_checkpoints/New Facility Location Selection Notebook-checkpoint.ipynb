{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Final Project:\n",
    "## New Facility Location Selection\n",
    "### by: Jeffrey Dupree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Introduction: Business Problem](#introduction)\n",
    "* [Data](#data)\n",
    "* [Methodology](#methodology)\n",
    "* [Analysis](#analysis)\n",
    "* [Results and Discussion](#results)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: Business Problem <a name=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will scrape neighborhood information from a ZIP-CODES.COM page https://www.zip-codes.com/state/fl.asp#zipcodes to create a dataframe consisting of the Zip Code, the City name, County name and the Zip Code type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data <a name=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we install the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't have these packages available, uncomment the appropriate lines below to install them.\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install beautifulsoup4\n",
    "!{sys.executable} -m pip install lxml\n",
    "!{sys.executable} -m pip install requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to get the information from the webpage using `requests.get`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = requests.get('https://www.zip-codes.com/state/fl.asp#zipcodes').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the BeautifulSoup package to scrape the information from the webpage. I used the lxml parsing method, but you can use any you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(source, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the table using `soup.find` from BeautifulSoup. Uncomment the second line to see the structure and content of the table. The tags are needed for the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table = soup.find(id=\"tblZIP\")\n",
    "# print(table.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a pandas dataframe needs to be created. This will require looping through the elements from the table and assigning the to a list. The list can then be made into a dataframe using `pd.DataFrame`. The columns will need header names. I manually assigned these instead of pulling them from the BeautifulSoup object `table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_rows = table.find_all('tr')\n",
    "\n",
    "res = []\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all('td')\n",
    "    row = [tr.text.strip() for tr in td if tr.text.strip()]\n",
    "    if row:\n",
    "        res.append(row)\n",
    "\n",
    "# Label the columns.\n",
    "df = pd.DataFrame(res[1:], columns=['Zip_Code','City','County','Type'])\n",
    "\n",
    "# Remove the text 'Zip Code' from the records in the Zip Code column.\n",
    "df['Zip_Code'] = df['Zip_Code'].str[-5:]\n",
    "\n",
    "# Select only the Zip Codes for Tampa, FL.\n",
    "df = df.loc[df['City'] == \"Tampa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next remove the rows where the type is \"P.O. Box\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove rows with Type = \"P.O. Box\" and \"Unique\", and reset the index to start at 0\n",
    "df = df[df.Type == 'Standard']\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataframe looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section Two: Geolocate ZIP Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "user_agent = \"JGD_20191006\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Uncomment next line to install geopy if necessary.\n",
    "!{sys.executable} -m pip install geopy\n",
    "\n",
    "from tqdm import tqdm #This will allow a progress bar to show that there is progress being made. This is helpful when an\n",
    "tqdm.pandas()         #iterative process may take more than a few seconds.\n",
    "\n",
    "from functools import partial #This will allow multiple arguments to be passed to RateLimiter.\n",
    "\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=user_agent)\n",
    "from geopy.extra.rate_limiter import RateLimiter #This will get around getting shut down for too many request errors.\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=0.5, max_retries=2, error_wait_seconds=5.0, swallow_exceptions=True, return_value_on_exception=None)\n",
    "df['location'] = df['Zip_Code'].progress_apply(partial(geocode, country_codes='us'))\n",
    "\n",
    "df['point'] = df['location'].apply(lambda loc: tuple(loc.point) if loc else None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[['Latitude','Longitude','3']] = pd.DataFrame(df['point'].tolist(), index=df.index)\n",
    "df = df.drop(columns=['point','3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are latitude and longitude values for each of the postal codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'] = df['location'].astype(str)\n",
    "df['location'] = df['location'].str.split(\", \").str[0].tolist()\n",
    "df = df.rename(columns={\"location\": \"Neighborhood\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Methodology <a name=\"methodology\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section Three: Locate Zip Codes Lacking Gyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # library to handle JSON files\n",
    "\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# Uncomment this line if you haven't installed folium for accessing the Foursquare API\n",
    "!conda install -c conda-forge folium=0.5.0 --yes\n",
    "import folium # map rendering library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create map of Tampa using latitude and longitude values\n",
    "tampa = geolocator.geocode({\"state\": \"fl\", \"city\": \"tampa\"})\n",
    "map_tampa = folium.Map(location=[tampa.latitude, tampa.longitude], zoom_start=10)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, county, city in zip(df['Latitude'], df['Longitude'], df['County'], df['City']):\n",
    "    label = '{}, {}'.format(county, city)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_tampa)  \n",
    "    \n",
    "map_tampa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "CLIENT_ID = 'MAI43NUPMV0YXXNFKS2XVGUPBMIB5SBO5T5W5FV4ZND2VTJW' # your Foursquare ID\n",
    "CLIENT_SECRET = 'V1POSAELWQ0NIURPOW2C43LH2FTO5NJ0VGYQXMSD2OGRLEND' # your Foursquare Secret\n",
    "VERSION = '20180604' # Foursquare API version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the url that will query the Foursquare API for the top 100 venues within 500 meters of the location. The cell above assigns the client ID and client secret to variables that will be called below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_lat = df.Latitude[0]\n",
    "search_lon = df.Longitude[0]\n",
    "LIMIT = 150 # Limit of number of venues returned by Foursquare API\n",
    "radius = 1000 # Define radius in meters\n",
    "\n",
    "# Create URL\n",
    "url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "    CLIENT_ID, \n",
    "    CLIENT_SECRET, \n",
    "    VERSION, \n",
    "    search_lat, \n",
    "    search_lon, \n",
    "    radius, \n",
    "    LIMIT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = requests.get(url).json()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that extracts the category of the venue\n",
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues = results['response']['groups'][0]['items']\n",
    "    \n",
    "nearby_venues = json_normalize(venues) # Flatten JSON\n",
    "\n",
    "# Filter columns\n",
    "filtered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\n",
    "nearby_venues =nearby_venues.loc[:, filtered_columns]\n",
    "\n",
    "# Filter the category for each row\n",
    "nearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n",
    "\n",
    "# Clean columns\n",
    "nearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n",
    "\n",
    "nearby_venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a function for using the Foursquare API to find the nearby venues for all of the boroughs in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=1000):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # Create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # Make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # Return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Zip_Code', \n",
    "                  'Zip Latitude', \n",
    "                  'Zip Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tampa_venues = getNearbyVenues(names=df['Zip_Code'],\n",
    "                                   latitudes=df['Latitude'],\n",
    "                                   longitudes=df['Longitude']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tampa_venues.shape)\n",
    "tampa_venues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tampa_venues['Venue Category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, there are several venue categories that could be generally categorized as a 'gym'. There are other venue categories that are not necesarily types of gyms, but might compete with a gym as a place where people go to be active. Another venue that would compete with a gym is 'Military Base'. Military bases have gyms and fitness centers for military members at no cost. We will need to recode these categories with a common category name (i.e., gym)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym = ['Gym / Fitness Center', 'Park', 'Martial Arts Dojo', 'Gym', 'Pool', 'Tennis Court', 'Disc Golf', 'Volleyball Court',\n",
    "       'Soccer Field', 'Basketball Court', 'Yoga Studio', 'College Basketball Court', 'College Gym','College Track',\n",
    "       'Dance Studio', 'Military Base', 'Athletics & Sports', 'Golf Course', 'Baseball Field', 'Trail', 'Hockey Arena',\n",
    "       'Hockey Field', 'Track', 'Water Park', 'Outdoors & Recreation', 'State / Provincial Park', 'Playground']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tampa_venues['Venue Category'].replace(to_replace =gym, value =\"Gym\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tampa_venues.groupby('Zip_Code').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} uniques categories.'.format(len(tampa_venues['Venue Category'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use one-hot encoding to determine if a venue type exists in a neighborhood. This will create a column for each of the unique categories, and assign a value of 1 if that venue type exists in the neighborhood or 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "tampa_onehot = pd.get_dummies(tampa_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# Add zip code column back to dataframe\n",
    "tampa_onehot['Zip_Code'] = tampa_venues['Zip_Code'] \n",
    "\n",
    "# Move zip code column to the first column\n",
    "fixed_columns = [tampa_onehot.columns[-1]] + list(tampa_onehot.columns[:-1])\n",
    "tampa_onehot = tampa_onehot[fixed_columns]\n",
    "\n",
    "tampa_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tampa_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the one-hot encoded data, we can determine the frequency with which each venue type occurs in each borough. This results in a dataframe with a column for each unique venue type and a row for each unique borough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tampa_grouped = tampa_onehot.groupby('Zip_Code').mean().reset_index()\n",
    "tampa_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will determine the five most frequent venues within a borough to describe a neighborhood 'type', and group the borough by type symilarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_top_venues = 5\n",
    "\n",
    "for hood in tampa_grouped['Zip_Code']:\n",
    "    print(\"----\"+hood+\"----\")\n",
    "    temp = tampa_grouped[tampa_grouped['Zip_Code'] == hood].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 5\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# Create columns according to number of top venues\n",
    "columns = ['Zip_Code']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# Create a new dataframe\n",
    "zip_venues_sorted = pd.DataFrame(columns=columns)\n",
    "zip_venues_sorted['Zip_Code'] = tampa_grouped['Zip_Code']\n",
    "\n",
    "for ind in np.arange(tampa_grouped.shape[0]):\n",
    "    zip_venues_sorted.iloc[ind, 1:] = return_most_common_venues(tampa_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "zip_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can see what the five most common venues are in each Zip Code are, we can eliminate those Zip Codes with 'gym' type venues in the top five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_venues_reduced = zip_venues_sorted[(zip_venues_sorted['1st Most Common Venue'] != 'Gym') & (zip_venues_sorted['2nd Most Common Venue'] != 'Gym') & \n",
    "                                       (zip_venues_sorted['3rd Most Common Venue'] != 'Gym') & (zip_venues_sorted['4th Most Common Venue'] != 'Gym') &\n",
    "                                       (zip_venues_sorted['5th Most Common Venue'] != 'Gym')]\n",
    "zip_venues_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the list only includes Zip Codes where 'gym' type venues are not one of the five most frequent venue types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = zip_venues_reduced.index\n",
    "locations = tampa_grouped[['Zip_Code','Gym']].iloc[index].sort_values(by=['Gym'], ascending=True)\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['Zip_Code']\n",
    "locations = locations.join(df.set_index(cols), on=cols)\n",
    "locations = locations.rename(columns={\"Gym\": \"Gym Frequency\"}).reset_index(drop=True)\n",
    "locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can display the locations on a map. Selecting a marker on the map will display that zip code and the frequency of 'gym' type venues within 1km of the zip code central point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create map\n",
    "map_locations = folium.Map(location=[tampa.latitude, tampa.longitude], zoom_start=11)\n",
    "\n",
    "# Set color scheme for the clusters\n",
    "x = np.arange(locations.shape[0])\n",
    "ys = [i + x + (i*x)**2 for i in range(locations.shape[0])]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# Add markers to the map\n",
    "markers_colors = []\n",
    "count = 0\n",
    "for lat, lon, poi, freq, nbh in zip(locations['Latitude'], locations['Longitude'], locations['Zip_Code'], \n",
    "                                    locations['Gym Frequency'], locations['Neighborhood']):\n",
    "    label = folium.Popup('Neigborhood: ' + str(nbh) + ' / Zip Code: ' + str(poi) + ' / Gym Frequency: ' + str(freq), \n",
    "                         parse_html=False,)\n",
    "    count = count + 1\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=7,\n",
    "        popup=label,\n",
    "        color=rainbow[count-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[count-1],\n",
    "        fill_opacity=0.7).add_to(map_locations)\n",
    "       \n",
    "map_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, json\n",
    "url = 'https://opendata.arcgis.com/datasets/d356e19e0fb34524b54d189fafb0d675_0.geojson'\n",
    "with urllib.request.urlopen(url) as url:\n",
    "    plt = json.loads(url.read().decode())\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install geojson\n",
    "import geojson\n",
    "from geojson import Feature, Point, FeatureCollection, MultiPolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the GeoJSON file from https://opendata.arcgis.com/datasets/d356e19e0fb34524b54d189fafb0d675_0.geojson polygons for the Zip Codes of intereset can be defined using the latitude and longitude coordinates. Below we create a list of coordinates for both latitudes and longitudes, then place these lists at the end of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in reversed(range(len(plt['features']))):\n",
    "    count = locations.shape[0]\n",
    "    for j in range(locations.shape[0]):\n",
    "        if plt['features'][i]['properties']['Zip_Code'] != locations['Zip_Code'][j]:\n",
    "            count = count - 1\n",
    "            if count == 0:\n",
    "                del plt['features'][i]\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Results <a name=\"results\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the polygons for the areas represented by the zip code can be overlaid on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create map\n",
    "map_test = folium.Map(location=[tampa.latitude, tampa.longitude], zoom_start=11)\n",
    "\n",
    "# Add polygons to the map\n",
    "for i in range(len(plt['features'])):\n",
    "    neighborhood = locations.Neighborhood[i]\n",
    "    zip_code = locations.Zip_Code[i]\n",
    "    geojson = folium.GeoJson(\n",
    "        plt['features'][i],\n",
    "        name=neighborhood\n",
    "    )\n",
    "    popup = folium.Popup(neighborhood + \" \" + zip_code)\n",
    "    popup.add_to(geojson)\n",
    "    geojson.add_to(map_test)\n",
    "\n",
    "folium.LayerControl().add_to(map_test)\n",
    "\n",
    "map_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(locations.Neighborhood[3] + \" \" + locations.Zip_Code[3])\n",
    "plt['features'][3]['properties']['Zip_Code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Discussion <a name=\"discussion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Conclusion <a name=\"conclusion\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
